{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nom682025-cell/Crazi-Di/blob/main/examples/%D0%9E%D0%B1%D1%83%D1%87%D0%B5%D0%BD%D0%B8%D0%B5%20%D0%B1%D0%B5%D0%B7%20%D1%83%D1%87%D0%B8%D1%82%D0%B5%D0%BB%D1%8F%20(%D0%BA%D0%BB%D0%B0%D1%81%D1%82%D0%B5%D1%80%D0%B8%D0%B7%D0%B0%D1%86%D0%B8%D1%8F%2C%20PCA).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRhVcj-0_CCs"
      },
      "outputs": [],
      "source": [
        "#импортируем библиотеки\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from mlxtend.plotting import plot_decision_regions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка данных"
      ],
      "metadata": {
        "id": "cwgqZpgNVhKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем датасет, подготовленный на предыдущих этапах обучения."
      ],
      "metadata": {
        "id": "0j_9O2LBbFB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, requests, urllib, io\n",
        "import pandas\n",
        "import os\n",
        "\n",
        "from google.colab import userdata\n",
        "pao = userdata.get('GITHUB_TOKEN_BIOMED_UPSKILL')\n",
        "user='AI-is-out-there'\n",
        "\n",
        "github_session = requests.Session()\n",
        "github_session.auth = (user, pao)\n",
        "\n",
        "# providing raw url to download csv from github\n",
        "csv_url = 'https://raw.githubusercontent.com/AI-is-out-there/biomed-upskill-dev/main/datasets/heart3.csv'\n",
        "\n",
        "download = github_session.get(csv_url).content\n",
        "raw_table_data = pandas.read_csv(io.StringIO(download.decode('utf-8')), header = 0)\n",
        "raw_table_data.head(3)"
      ],
      "metadata": {
        "id": "nMwZdLpEZ_yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#смотрим размерность датасета\n",
        "raw_table_data.shape"
      ],
      "metadata": {
        "id": "CaTtY-SbIXZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Helicopter view"
      ],
      "metadata": {
        "id": "J8wsk52ln5ah"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#смотим данные датасета в табличном виде - первые пять строк\n",
        "table_data = raw_table_data\n",
        "table_data.head()"
      ],
      "metadata": {
        "id": "iZYfqv7dn_tV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#статистические параметры распределения по столбцам\n",
        "table_data.describe()"
      ],
      "metadata": {
        "id": "b9h21UlaoMBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#проверяем распределение целевого признака\n",
        "sns.countplot(data=table_data, x=\"ССЗ\")\n",
        "plt.title(\"Распределение целевой переменной 'ССЗ'\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vHJXFSxibPaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Визуализация распределения значений датасета"
      ],
      "metadata": {
        "id": "nrOLNRh1oV62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = table_data.shape[1]  # Количество столбцов\n",
        "cols_per_row = 4  # Сколько графиков в одной строке\n",
        "n_rows = (n + cols_per_row - 1) // cols_per_row  # Вычисляем количество строк\n",
        "\n",
        "fig, axes = plt.subplots(\n",
        "    n_rows,\n",
        "    cols_per_row,\n",
        "    figsize=(cols_per_row * 4, n_rows * 3),  # Размер фигуры (ширина, высота)\n",
        "    squeeze=False  # Гарантирует, что axes всегда будет двумерным массивом\n",
        ")\n",
        "\n",
        "# Убираем лишние оси, если столбцов не кратно cols_per_row\n",
        "for i in range(n, n_rows * cols_per_row):\n",
        "    fig.delaxes(axes.flatten()[i])\n",
        "\n",
        "# Строим боксплоты\n",
        "for i, col in enumerate(table_data.columns):\n",
        "    row_idx = i // cols_per_row\n",
        "    col_idx = i % cols_per_row\n",
        "    ax = axes[row_idx, col_idx]\n",
        "\n",
        "    sns.boxplot(\n",
        "        y=table_data.iloc[:, i],\n",
        "        data=table_data,\n",
        "        ax=ax,\n",
        "        medianprops={\"color\": \"r\", \"linewidth\": 2}\n",
        "    )\n",
        "    ax.set_title(col, fontsize=10)  # Подпись графика\n",
        "\n",
        "plt.tight_layout()  # Автоматическая настройка отступов\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sa79MTvc_Kj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#проверяем корреляцию признаков\n",
        "\n",
        "sns.heatmap(table_data.corr(),annot=True,fmt=\"0.2f\",cmap=\"coolwarm\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OAvT3HE9dWaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#изобразим только те значения, которые имеют значительную корреляцию\n",
        "df_corr_table = table_data.corr()\n",
        "mask_con_corr = df_corr_table[(df_corr_table >= 0.50) | (df_corr_table <= -0.50)]\n",
        "\n",
        "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(15,15))\n",
        "fig = sns.heatmap(mask_con_corr, vmin=-1, vmax=1, annot=True, fmt='0.2f')\n",
        "fig.set_title(\"Тепловая карта корреляции (уровень 1/2)\")"
      ],
      "metadata": {
        "id": "qKHBNRATeBqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Методы PCA - princopal component analysis"
      ],
      "metadata": {
        "id": "oghonn2LlqIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "NOW14_BJl0GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_data_pca = table_data\n",
        "table_data_pca = table_data_pca.drop('ССЗ', axis = 1)\n",
        "table_data_pca.columns"
      ],
      "metadata": {
        "id": "LHuHlty5sqvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Before applying PCA, each feature should be centered (zero mean) and with unit variance\n",
        "scaled_data = StandardScaler().fit(table_data_pca).transform(table_data_pca)\n",
        "\n",
        "#pca = PCA(n_components = 2).fit(scaled_data) #количество компонет\n",
        "\n",
        "pca = PCA(n_components = 0.7).fit(scaled_data) #значение дисперсии, которое определит необходимое количество компонент\n",
        "\n",
        "x_pca = pca.transform(scaled_data)\n",
        "print(table_data.shape, x_pca.shape)"
      ],
      "metadata": {
        "id": "Daf1yBuWpmWf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "percent = pca.explained_variance_ratio_\n",
        "print(percent)\n",
        "print(sum(percent))\n",
        "#To see how much variance is preserved for each dataset."
      ],
      "metadata": {
        "id": "qpe_oWN9qDRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pca_explained(X, threshold):\n",
        "  features = X.shape[1]\n",
        "  for i in range(2, features):\n",
        "    pca = PCA(n_components = i).fit(X)\n",
        "    sum_ = pca.explained_variance_ratio_\n",
        "    # add all components explained variances\n",
        "    percent = sum(sum_)\n",
        "    print('{} components at {:.2f}% explained variance'.format(i,percent*100))\n",
        "    if percent > threshold:\n",
        "      break\n",
        "\n",
        "pca_explained(scaled_data, 0.85)"
      ],
      "metadata": {
        "id": "ScKB0mzkqKbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(x_pca[:,0], x_pca[:,1], c=table_data['ССЗ'], cmap='plasma', alpha=0.4, edgecolors='black', s=65);\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')"
      ],
      "metadata": {
        "id": "YtRUOaP3q0Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ICA independed component analysis"
      ],
      "metadata": {
        "id": "hx9My_uNGFum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import FastICA\n",
        "\n",
        "ICA = FastICA(n_components=2)\n",
        "scaled_data_ica = ICA.fit_transform(scaled_data)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(scaled_data_ica[:,0],\n",
        "            scaled_data_ica[:,1],\n",
        "            c=table_data['ССЗ'],\n",
        "            cmap='plasma',\n",
        "            alpha=0.4,\n",
        "            edgecolors='black',\n",
        "            s=65\n",
        "            );\n",
        "plt.xlabel('First Independed Component')\n",
        "plt.ylabel('Second Independed Component')"
      ],
      "metadata": {
        "id": "IJyUBCgGGCfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Кластеризация"
      ],
      "metadata": {
        "id": "TDO3cuNt0fIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "pca_data = pd.DataFrame(x_pca[:,0:2],columns=['PC1','PC2'])\n",
        "\n",
        "\n",
        "kmeans = KMeans(n_clusters=4).fit(scaled_data)\n",
        "pca_data['cluster'] = pd.Categorical(kmeans.labels_)\n",
        "sns.scatterplot(x=\"PC1\",y=\"PC2\",hue=\"cluster\",data=pca_data)"
      ],
      "metadata": {
        "id": "RC__1YbjwxbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_data.shape[1]"
      ],
      "metadata": {
        "id": "ZOPviZqg0w-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wcss=[]\n",
        "#WCSS (Within-Cluster Sum of Squares) is a metric used to evaluate the compactness of clusters.\n",
        "num_cluster = scaled_data.shape[1]\n",
        "for i in range(1,num_cluster):\n",
        "    kmeans=KMeans(n_clusters=i, init='k-means++', random_state=37)\n",
        "    kmeans.fit(scaled_data)\n",
        "    wcss.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.plot(range(1,num_cluster), wcss)\n",
        "plt.xlabel(\"Number of Clusters\")\n",
        "plt.ylabel(\"WCSS\")\n",
        "plt.title(\"K-Means Clustering\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1nlQgmZU0j_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kmeans = KMeans(n_clusters=4).fit(scaled_data)\n",
        "\n",
        "df_segm_kmeans=table_data_pca.copy()\n",
        "df_segm_kmeans['Segment k-Means']=kmeans.labels_\n",
        "df_segm_analysis=df_segm_kmeans.groupby(['Segment k-Means']).mean()\n",
        "df_segm_analysis\n"
      ],
      "metadata": {
        "id": "x5r0V3881q_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_segm_kmeans"
      ],
      "metadata": {
        "id": "Ds5UhyMf5kKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_segm_analysis['N-obs']=df_segm_kmeans[['ЛПВП','Segment k-Means']].groupby(['Segment k-Means']).count()\n",
        "df_segm_analysis['Prop-obs']=df_segm_analysis['N-obs']/df_segm_analysis['N-obs'].sum()\n",
        "\n",
        "x_axis=df_segm_kmeans['Холестерин']\n",
        "y_axis=df_segm_kmeans['Индекс массы тела, кг/м^2']\n",
        "plt.figure(figsize=(12,9))\n",
        "colors = ['r', 'g', 'b', 'y']\n",
        "sns.scatterplot(x=x_axis,y=y_axis, hue=df_segm_kmeans['Segment k-Means'], palette=colors)\n",
        "plt.title(\"Segmented K-Means\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KI-3akVs45VG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# put feature values into dataframe\n",
        "\n",
        "plt.figure(figsize=(10,8))\n",
        "# main scatterplot\n",
        "plt.scatter(x_pca[:,0], x_pca[:,1], c=table_data['ССЗ'],\n",
        "            cmap='plasma', alpha=0.4, edgecolors='black', s=40);\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')\n"
      ],
      "metadata": {
        "id": "wdRhrRvv96tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(8, 4))\n",
        "plt.imshow(pca.components_, interpolation = 'none', cmap = 'plasma')\n",
        "feature_names = list(table_data_pca.columns)\n",
        "plt.gca().set_xticks(np.arange(-.5, len(feature_names)-1));\n",
        "plt.gca().set_yticks(np.arange(0.5, 2));\n",
        "plt.gca().set_xticklabels(feature_names, rotation=90, ha='left',fontsize=12);\n",
        "plt.gca().set_yticklabels(['First PC', 'Second PC'], va='bottom',fontsize=12);\n",
        "plt.colorbar(orientation='horizontal', ticks=[pca.components_.min(), 0,\n",
        "                                              pca.components_.max()],pad=0.65);"
      ],
      "metadata": {
        "id": "bYxedjn9rZvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MDS t-SNE"
      ],
      "metadata": {
        "id": "1c_7BPFwBwPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import MDS"
      ],
      "metadata": {
        "id": "ik-KlYsDB12J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mds = MDS(n_components = 2)\n",
        "scaled_data_mds = mds.fit_transform(scaled_data)\n",
        "\n",
        "plt.scatter(scaled_data_mds[:,0], scaled_data_mds[:,1], c=table_data['ССЗ'], cmap='plasma', alpha=0.4, edgecolors='black', s=65);\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')"
      ],
      "metadata": {
        "id": "iWdOmBO3BvQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "tsne = TSNE(random_state=0, perplexity=10)\n",
        "scaled_data_mds_tsne = tsne.fit_transform(scaled_data)\n",
        "plt.scatter(scaled_data_mds_tsne[:,0], scaled_data_mds_tsne[:,1], c=table_data['ССЗ'], cmap='plasma', alpha=0.4, edgecolors='black', s=65);\n",
        "plt.xlabel('First Principal Component')\n",
        "plt.ylabel('Second Principal Component')"
      ],
      "metadata": {
        "id": "-maG5b_vCXd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from scipy.cluster.hierarchy import ward, dendrogram, fcluster"
      ],
      "metadata": {
        "id": "1ywzks59DhYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scaled_data, data_table['Healthy_status'] = make_blobs(random_state = 10)\n",
        "#n_clusters must be None if distance_threshold is not None\n",
        "cls = AgglomerativeClustering(n_clusters = 3,linkage='ward', distance_threshold=None)\n",
        "cls_assignment = cls.fit_predict(scaled_data)"
      ],
      "metadata": {
        "id": "yo7N3PGvNCtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Z = ward(scaled_data)\n",
        "plt.figure(figsize=(17,5));\n",
        "R = dendrogram(Z, truncate_mode='lastp', p=7, orientation='top', leaf_font_size=8)\n",
        "plt.title('Hierarchical Clustering Dendrogram (truncated and grouped)')\n",
        "plt.xlabel('sample index')\n",
        "plt.ylabel('distance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Kj4PTC8iDgsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Affinity propagation"
      ],
      "metadata": {
        "id": "-RN1d68G7oe3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.cluster import AffinityPropagation\n",
        "from sklearn.metrics import adjusted_rand_score"
      ],
      "metadata": {
        "id": "zJtLKlwC7kEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_connected_points(X, labels, centers, cmap):\n",
        "    for i in range(len(X)):\n",
        "        color = cmap(labels[i] / len(centers))\n",
        "        plt.plot([X[i, 0], centers[labels[i], 0]], [X[i, 1], centers[labels[i], 1]], c=color, alpha=0.8)"
      ],
      "metadata": {
        "id": "hM1nIqA39cJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sk_ap = AffinityPropagation()\n",
        "sk_ap_pred_res = sk_ap.fit_predict(scaled_data)\n",
        "sk_ap_ari = adjusted_rand_score(table_data['ССЗ'], sk_ap_pred_res)\n",
        "print(f'Adjusted Rand Score for sk AffinityPropagation: {sk_ap_ari}', '', sep='\\n')\n",
        "print('Number of clusters = ', np.max(sk_ap_pred_res))\n",
        "#print('prediction', sk_ap_pred_res, sep='\\n')"
      ],
      "metadata": {
        "id": "rmhlrlH87meZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.scatter(scaled_data[:, 0], scaled_data[:, 1], c=sk_ap_pred_res, cmap='rainbow', s=10)\n",
        "plt.scatter(sk_ap.cluster_centers_[:, 0], sk_ap.cluster_centers_[:, 1], c='black', s=50)\n",
        "plt.title('AffinityPropagation (scikit-learn)')\n",
        "plt.xlabel(table_data.columns[5])\n",
        "plt.ylabel(table_data.columns[29])\n",
        "\n",
        "plot_connected_points(scaled_data, sk_ap_pred_res, sk_ap.cluster_centers_, plt.cm.rainbow)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2ZufeLbT9JdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agglomerative Clustering"
      ],
      "metadata": {
        "id": "yhXp0TRUPnjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.cluster.hierarchy import dendrogram\n",
        "\n",
        "from sklearn.cluster import AgglomerativeClustering"
      ],
      "metadata": {
        "id": "k0A7JLGCPrPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_dendrogram(model, **kwargs):\n",
        "    # Create linkage matrix and then plot the dendrogram\n",
        "\n",
        "    # create the counts of samples under each node\n",
        "    counts = np.zeros(model.children_.shape[0])\n",
        "    n_samples = len(model.labels_)\n",
        "    for i, merge in enumerate(model.children_):\n",
        "        current_count = 0\n",
        "        for child_idx in merge:\n",
        "            if child_idx < n_samples:\n",
        "                current_count += 1  # leaf node\n",
        "            else:\n",
        "                current_count += counts[child_idx - n_samples]\n",
        "        counts[i] = current_count\n",
        "\n",
        "    linkage_matrix = np.column_stack(\n",
        "        [model.children_, model.distances_, counts]\n",
        "    ).astype(float)\n",
        "\n",
        "    # Plot the corresponding dendrogram\n",
        "    #plt.figure(figsize=(17,5));\n",
        "    dendrogram(linkage_matrix, **kwargs)\n",
        "    plt.rcParams[\"figure.figsize\"] = (17,5)\n",
        "    plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "Z_bqQelSPwJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting distance_threshold=0 ensures we compute the full tree.\n",
        "model = AgglomerativeClustering(distance_threshold=0, n_clusters=None)\n",
        "\n",
        "model = model.fit(scaled_data)\n",
        "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
        "# plot the top three levels of the dendrogram\n",
        "plot_dendrogram(model, truncate_mode=\"level\", p=3)\n",
        "#"
      ],
      "metadata": {
        "id": "E9ZypW_OPmu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# дополнительная секция - расширенная программа со специальными приемами машинного обучения"
      ],
      "metadata": {
        "id": "lLGwujYvjZNK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML-классификация: модель GaussianNaiveBayes"
      ],
      "metadata": {
        "id": "nO-t2hxZWGnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "#GaussianNaiveBayes"
      ],
      "metadata": {
        "id": "8VXMXvCV91Ed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the classification index of table\n",
        "clf_index = 33\n",
        "\n",
        "# classification variable\n",
        "y1 = table_data.iloc[:, clf_index]\n",
        "# input variable\n",
        "X1 = table_data.drop(table_data.columns[[clf_index]], axis=1).iloc[:,:]\n",
        "\n",
        "y1 = pd.Series(LabelEncoder().fit_transform(y1))\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1.values,\n",
        "                                                        y1.values,\n",
        "                                                        test_size=0.3,\n",
        "                                                        random_state=37,\n",
        "                                                        stratify=y1.values)"
      ],
      "metadata": {
        "id": "g_BSmq9vAAe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def decision_boundary_plot(X, y, X_train, y_train, clf, feature_indexes, title=None):\n",
        "    feature1_name, feature2_name = X.columns[feature_indexes]\n",
        "    X_feature_columns = X.values[:, feature_indexes]\n",
        "    X_train_feature_columns = X_train[:, feature_indexes]\n",
        "    clf.fit(X_train_feature_columns, y_train)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plot_decision_regions(X=X_feature_columns, y=y.values, clf=clf)\n",
        "    plt.xlabel(feature1_name)\n",
        "    plt.ylabel(feature2_name)\n",
        "    plt.title(title)"
      ],
      "metadata": {
        "id": "GXTkvxgm-6cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_data.columns"
      ],
      "metadata": {
        "id": "TdcIBbgn_avj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sk_nb_clf = GaussianNB()\n",
        "sk_nb_clf.fit(X1_train, y1_train)\n",
        "sk_nb_clf_pred_res = sk_nb_clf.predict(X1_test)\n",
        "sk_nb_clf_accuracy = accuracy_score(y1_test, sk_nb_clf_pred_res)\n",
        "\n",
        "print(f'sk Naive Bayes classifier accucacy: {sk_nb_clf_accuracy}')\n",
        "print(sk_nb_clf_pred_res)\n",
        "\n",
        "feature_indexes = [5, 29]\n",
        "title1 = 'GaussianNB surface'\n",
        "decision_boundary_plot(X1, y1, X1_train, y1_train, sk_nb_clf, feature_indexes, title1)"
      ],
      "metadata": {
        "id": "XOM1mI2hApEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML - Описание классов и матрица ошибок"
      ],
      "metadata": {
        "id": "44INZ-bbW4fc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "from sklearn.metrics import classification_report,confusion_matrix"
      ],
      "metadata": {
        "id": "Y0V7wknfK0zx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_data.columns"
      ],
      "metadata": {
        "id": "sis68QmPIQNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the classification index of table\n",
        "clf_index = 33"
      ],
      "metadata": {
        "id": "JCcfCdI4IJfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(35,20),dpi=90)\n",
        "# Plot frequency percentages barplot\n",
        "table_data[table_data.columns[clf_index]].value_counts(normalize=True).mul(100).plot(kind='barh', width=0.8, figsize=(8,5))\n",
        "\n",
        "# Add frequency percentages to the plot\n",
        "labels = table_data[table_data.columns[clf_index]].value_counts(normalize=True).mul(100).round(1)\n",
        "for i in labels.index:\n",
        "    plt.text(labels[i], i, str(labels[i])+ '%', fontsize=15, weight='bold')\n",
        "\n",
        "plt.xlim([0, 110])\n",
        "plt.xlabel('Frequency Percentage', fontsize=13)\n",
        "plt.ylabel(table_data.columns[clf_index], fontsize=13)\n",
        "plt.title('Frequency Percentage of Target Classes', fontsize=13)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A4Lj4ckRMV4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the classification index of table\n",
        "clf_index = 33\n",
        "\n",
        "# classification variable\n",
        "y1 = table_data.iloc[:, clf_index]\n",
        "# input variable\n",
        "X1 = table_data.drop(table_data.columns[[clf_index]], axis=1).iloc[:,:]\n",
        "\n",
        "y1 = pd.Series(LabelEncoder().fit_transform(y1))\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1.values,\n",
        "                                                        y1.values,\n",
        "                                                        test_size=0.3,\n",
        "                                                        random_state=0,\n",
        "                                                        stratify=y1.values)"
      ],
      "metadata": {
        "id": "esN8Cmya7apd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X1.values,\n",
        "                                                 y1.values,\n",
        "                                                 test_size=0.3,\n",
        "                                                 random_state=41,\n",
        "                                                 stratify=y1.values)\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "metadata": {
        "id": "Ec_q_TrULn8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GussianClassifier = GaussianNB()\n",
        "GussianClassifier.fit(X1_train,y1_train)\n",
        "y_pred=GussianClassifier.predict(X_test)\n",
        "print(\"===================================> Result <===================================\")\n",
        "print(\"Accuracy                     = \" ,metrics.accuracy_score(y_test,y_pred))\n",
        "print(\"F1 Score                     = \" ,metrics.f1_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "ZDK5KdEBKNMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "5RlIDQWITKs7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['True', 'False']\n",
        "labels_names = [0,1]\n",
        "print(classification_report(y_test, y_pred,labels=labels_names, target_names=target_names))\n",
        "#cm = confusion_matrix(y_test, y_pred,labels=labels_names,normalize='true')\n",
        "cm = confusion_matrix(y_test, y_pred,labels=labels_names)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=target_names)\n",
        "disp = disp.plot(cmap=plt.cm.Blues,values_format='g')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LgY_9JoySn98"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}